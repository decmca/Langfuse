# Evaluation Metrics Configuration

# Batch Processing Configuration
batch_processing:
  enabled: true
  default_batch_size: 8
  max_batch_size: 16
  adaptive_batching: false  # Future: auto-adjust based on GPU memory

# Retrieval configuration
retrieval:
  top_k: 5
  # Add batch retrieval if your retriever supports it
  batch_retrieval: true

# Generation configuration
generation:
  # Batch generation settings
  batch_size: 8
  max_new_tokens: 512
  temperature: 0.7
  top_p: 0.9
  do_sample: true

retrieval_metrics:
  metrics:
    - "precision@k"
    - "recall@k"
    - "mrr"  # Mean Reciprocal Rank
    - "ndcg@k"  # Normalised Discounted Cumulative Gain
    - "map"  # Mean Average Precision
  k_values: [1, 3, 5, 10]

generation_metrics:
  metrics:
    - "rouge"  # ROUGE-1, ROUGE-2, ROUGE-L
    - "bleu"
    - "exact_match"
    - "f1_score"
    - "bertscore"
  llm_judge:
    enabled: false
    model: "gpt-4o-mini"
    metrics:
      - "answer_relevancy"
      - "faithfulness"
      - "correctness"

citation_metrics:
  - "citation_coverage"  # % of statements with citations
  - "citation_support_rate"  # % of citations that support the statement
  - "citation_precision"  # % of retrieved docs that are cited
  - "citation_recall"  # % of relevant docs that are cited
  - "citation_contradiction_rate"  # % of citations that contradict the statement

performance_metrics:
  - "latency_p50"
  - "latency_p95"
  - "latency_p99"
  - "tokens_per_second"
  - "gpu_memory_peak_gb"

langfuse_tracking:
  enabled: true
  log_traces: true
  log_spans: true
  log_metrics: true
  batch_size: 10
